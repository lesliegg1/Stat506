\documentclass{article}
\usepackage{float}
\usepackage{amsmath}

  %% LaTeX margin settings:
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{9in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\topmargin}{-1.5cm}
\setlength{\maxwidth}{6.5in}

\newcommand{\R}{{\sf R}}
\newcommand{\bfbeta}{\mbox{\boldmath $\beta$}}
\newcommand{\bfep}{\mbox{\boldmath $\epsilon$}}
\newcommand{\bfD}{\mbox{\boldmath $D$}}
\newcommand{\bfL}{\mbox{\boldmath $L$}}
\newcommand{\bfR}{\mbox{\boldmath $R$}}
\newcommand{\bfmu}{\mbox{\boldmath $\mu$}}
\newcommand{\bfV}{\mbox{\boldmath $V$}}
\newcommand{\bfX}{\mbox{\boldmath $X$}}

\newcommand{\bfy}{\mbox{\boldmath $y$}}
\newcommand{\bfz}{\mbox{\boldmath $z$}}
\newcommand{\bfSig}{\mbox{\boldmath $\Sigma$}}
\newcommand{\tr}{^{\sf T}}
\newcommand{\inv}{^{-1}}


\begin{document}

<<setup, include=FALSE, cache=FALSE>>=
opts_chunk$set(fig.width=5, fig.height=4, out.width='\\linewidth', dev='pdf', concordance=TRUE, size='footnotesize')
options(replace.assign=TRUE,width=72, digits = 3, 
        show.signif.stars = FALSE)

require(xtable)
display.xtable <- function(lmobj, ...){
  sumry <- summary(lmobj)
  captn <- paste("n = ", lmobj$df.residual + lmobj$rank,
                      " rank = ", lmobj$rank)
  if(class(lmobj)[1] == "lm")
      captn <- paste(captn, " resid sd = ", round(sumry$sigma, options()$digits),
                      " R-Squared = ", round( sumry$r.squared, options()$digits))
  else if(class(lmobj)[1] == "glm")
      captn <- paste(captn, " Resid Deviance = ", round(sumry$deviance, options()$digits))
  xtable(sumry$coef[,1:3, drop=FALSE], caption = captn, ...)
}
@


\large
\begin{center}
{\Large \bf  Stat 506 Assignment 9 \vspace{.2in}} \\ 
{\it Leslie Gains-Germain}
\date{\today}
\end{center}

\begin{enumerate}

\item Two medications are designed to lower systolic blood pressure (SBP) for subjects with high blood pressure. Medication A has been shown to lower blood pressure by 30 units (on average) with subject-to-subject variance of 2 $units^2$, and has been approved by the FDA. The makers of medication B would like to show that it is as effective as Medication A, that is, to show that the mean difference between the medications is in the interval $(-1, 1)$ units. High blood pressure is a risk factor for stroke and heart attack so the subjects, who all suffer from high blood pressure if untreated, cannot be given a placebo. A cross-over design will be used with random allocation of the first medication (A or B) followed two weeks later by the other medication.

\begin{enumerate}

\item The variable of interest will be the difference in mean blood pressure, SBP-A minus SBP-B. Write a formula for its variance assuming B and A are equally effective, and that the two measurements on the same person have correlation: $\rho$.

\begin{align*}
Var[\bar{x}_A-\bar{x}_B] &= Var[\bar{x}_A]+Var[\bar{x}_B]-2Cov[\bar{x}_A,\bar{x}_B] \\
Var[\bar{x}] &= \frac{\sum Var[x_i]}{J^2} = \frac{\sigma_T^2}{J} \\
Var[\bar{x}_A-\bar{x}_B] &=\frac{\sigma^2_T}{J}+\frac{\sigma^2_T}{J}-2\rho\frac{\sigma_T}{\sqrt{J}}\frac{\sigma_T}{\sqrt{J}} = \frac{4}{J}-\frac{4\rho}{J} \\
\end{align*}

{\it where $J$ is the number of subjects, and one measurement is taken on each person for each medication. $\sigma^2_T$ is assumed to be $2$.}

\item Use a stat package to draw a picture of the distributions of interest under the null hypothesis of no difference and under the alternative of interest: $\mu_A-\mu_B$=1 unit. (Take $\rho=0$ for simplicity) \\

{\it I show the distributions of the t-statistics under the null and alternative hypotheses for sample sizes between $10$ and $80$.}

<<draw, echo=FALSE, fig.width=12>>=
nulldiff <- 0

altdiff <- 1

J <- seq(10,80, 10)

plot.fun <- function(J) {
x <- seq(-6,10,.001)
plot(x, dt(x, J-1), cex=.01, xlim=c(-3,10), main=paste("J=",J), ylab="t density") 
lines(x, dt(x, J-1, sqrt(J/4)), lty=2)}

par(mfrow=c(2,4))
invisible(sapply(as.list(J), plot.fun))
@

\item Use pt and qt functions in R to compute the power of the test if 25 subjects are used and the testing is done with a significance level of $\alpha=.05$ for a two-sided rejection region. (show code) 

<<powercalc, echo=TRUE>>=
pt(qt(0.025,24), 24, ncp=(5/2))+(1-pt(qt(0.975,24), 24, ncp=(5/2)))
power.t.test(n=25, delta=1, sd=2, sig.level=0.05, power=NULL, type=("paired"))
@

{\it The power is estimated to be $0.67$.}

\item Why might regulators insist on a smaller probability of type II error than the probability of type I error? \\

{\it A type I error occurs if we conclude that medication B is not as effective as medication A, when in fact it is. If a type I error occured, it would unfortunate for the company that produces medication B because the product would be rejected. But, there would be no impact on consumers. \\ 

A type II error occurs if we conclude that medication B is as effective as medication A when in fact it is not. A type II error would have more of an impact because medication B would be approved for sale. In this case, consumers would be buying a less effective medication without knowing it. \\

Regulators will most likely insist on a smaller probability of type II error than type I error because a type II error would have a greater impact on consumers. }

\item What minimum sample size is needed to bring the power up to at least 0.95? 

<<bringpower, echo=FALSE>>=
J <- rep(0, 56)
power <- rep(0, 56)
for(i in 25:80){
J[i-24]<-i
power[i-24] <- pt(qt(0.025,i-1), i-1, ncp=(sqrt(i)/2))+(1-pt(qt(0.975,i-1), i-1, ncp=(sqrt(i)/2)))
}
power.n <- cbind.data.frame(J, power)
require(xtable)
power.n[23:32,]
@

<<ttest, echo=FALSE>>=
power.t.test(delta=1, sd=2, sig.level=0.05, power=0.95, type=("paired"))
@


{\it We need a sample size of at least $54$ to bring the power up to $0.95$.}

\item How would things change if we used two independent groups of subjects: one getting SBP-A, the other (randomly assigned) SBP-B. Measurement is difference in SBP (before treatment - after treatment).

<<sd, echo=FALSE>>=
power.t.test(delta=1, sd=sqrt(2), sig.level=0.05, power=0.95, type=("two.sample"))
@

{\it We would need twice as many people, about $53$ in each medication group (A and B) to achieve the same power as we did in the paired design.}

\end{enumerate}

\item Researchers are aware of many variables which are expected to affect y= the growth of calves in their first three months. These background variables use 5 degrees of freedom and are thought to account for 20\% of the variation in y between calves. The researchers plan to study effects of dietary supplements fed to the mother cows, and have three formulations in mind. They come to you to ask about how many cow-calf pairs they should use in the study. [Aside: to keep the unit of the study distinct, cows will have to be randomly assigned treatments, not pens or herds of cows.] An important effect would be if the feeds explain an additional 5\% of the variation in y. 

\begin{enumerate}
\item After collecting the data, the analysis will compute an F test to assess the impact of feeds after adjusting for the background variables. Assuming we have n pairs in each treatment group, what are the numerator and denominator degrees of freedom for the F test? \\
{\it The numerator degrees of freedom would be $2$ and the denominator degrees of freedom would be $n-8$.}
\item Using Cohenâ€™s derivation, compute the non-centrality parameter, $\lambda$, as a function of $n$. \\
$\lambda = \frac{0.25-0.2}{1-0.25}(2+(n-8)+1)=\frac{1}{15}(n-5)$

\item If the researchers use $\alpha=0.05$, how large will each group of pairs need to be to achieve power of 90\%? 

<<powercows, echo=TRUE, message=FALSE>>=
n <- rep(0, 201)
power <- rep(0, 201)
for(i in 50:250){
n[i-49]<-i
power[i-49] <- 1-pf(qf(0.95,2,i-8),2, i-8, ncp=(1/15*(i-5)))
}
cbind.data.frame(n,power)[146:153,]
require(pwr)
#pwr.anova.test(f=sqrt(1/15), k=3, power=0.9, sig.level=0.05)
#64.27981
@

{\it My power analysis suggests that $198$ calf cow pairs, $66$ in each group, are required to achieve a power of $90\%$ at a significance level of $0.05$. The \verb+pwr.anova.test+ function says that a sample size of $65$ pairs in each group will achieve a power of $90\%$ (pretty close).}


\end{enumerate}

\item Exercise 5 in ARM Chapter 20 asks us to look back at the Electric Company data in Chapter 9. Remember that the treatment unit is a class of students. I think it would be of interest to detect a shift in mean of 5 points for the second graders. Use $\alpha=0.05$ as they suggest and target power of 80\%.

\begin{enumerate}
\item State all assumptions.

{\it The sample standard deviations in the existing Electric Company data for the control and treated groups in the second grade are $12$ and $10$, respectively. For the power analysis, I'll assume a pooled standard deviation of $11$, and I'll assume equal sample sizes in treated and control groups. We also assume that the population distributions of scores for both the control and treated groups are normally distributed, and we assume independence among class test scores. Lastly, we assume that the mean score of the treated group is five points higher than the non-treated group.}

\item Simply compare the average of treated classes with the average for controls. (ignore the repeated measures aspect of the data.)


<<bringpowerclass, echo=FALSE>>=
J <- rep(0, 176)
power <- rep(0, 176)
for(i in 25:200){
J[i-24]<-i
power[i-24] <- pt(qt(0.025,i-2), i-2, ncp=5*sqrt(i)/(11*sqrt(4)))+1-pt(qt(0.975,i-2), i-2, ncp=5*sqrt(i)/(11*sqrt(4)))
}
power.n <- cbind.data.frame(J, power)
require(xtable)
power.n[125:135,]
#pt(qt(0.025,143), 143, ncp=5*sqrt(145)/(11*sqrt(4)))+1-pt(qt(0.975,143), 143, ncp=5*sqrt(145)/(11*sqrt(4)))
@

<<ttestclass, echo=FALSE>>=
power.t.test(delta=5, sd=11, sig.level=0.05, power=0.80, type=("two.sample"))
@

{\it Both my function and the \verb+power.t.test+ function suggest that a sample size of $154$ total, $77$ in each group, is needed to achieve a power of $80\%$.}

\item Do the same with average gain scores. 

{\it The Electric Company data shows that the sample standard deviation of each group is approximately $6$, and again I'll assume the same sample sizes in each group. I'll assume that we also want to detect a difference of $5$ in the average gain scores as well. Both my function and the power.t.test function suggest that a sample of $48$ total, $24$ in each group, is needed to achieve a power of $80\%$.}

<<bringpowergain, echo=FALSE>>=
J <- rep(0, 176)
power <- rep(0, 176)
for(i in 25:200){
J[i-24]<-i
power[i-24] <- pt(qt(0.025,i-2), i-2, ncp=5*sqrt(i)/(6*sqrt(4)))+1-pt(qt(0.975,i-2), i-2, ncp=5*sqrt(i)/(6*sqrt(4)))
}
power.n <- cbind.data.frame(J, power)
require(xtable)
power.n[21:29,]
#pt(qt(0.025,143), 143, ncp=5*sqrt(145)/(11*sqrt(4)))+1-pt(qt(0.975,143), 143, ncp=5*sqrt(145)/(11*sqrt(4)))
@

<<ttestgain, echo=FALSE>>=
power.t.test(delta=5, sd=6, sig.level=0.05, power=0.80, type=("two.sample"))
@

\item Do the same in a regression context using pretest as predictor and simulating as in section 20.5. 

{\it I first fit a regression of posttest score on pretest and treatment for second grade classrooms. I then used the estimated regression model to simulate post test scores for simulated pretest scores in the treated/control groups.}

<<sim, echo=FALSE, message=FALSE, cache=TRUE, echo=TRUE>>=
electric <- read.csv("~/Documents/Stat506/Homework/HW9/electricComp.csv")
require(dplyr)
electric2 <- electric %>%
  filter(grade==2)
electric2$trt <- factor(electric2$trt, levels=c("untreated", "treated"))
lm.elec2 <- lm(posttest~pretest+trt, data=electric2)

electric.fake <- function(n){
  class <- 1:n
  treatment <- sample(rep(0:1, n/2))
  
  sigma <- 5.479
  
  #mean(electric2$pretest)
  #sd(electric2$pretest)
  pretest <- rnorm(n, 73.3, 12.47)
  
  posttest <- rnorm(n, coef(lm.elec2)[1]+coef(lm.elec2)[2]*pretest+
                 coef(lm.elec2)[3]*treatment, sigma)
  return(data.frame(class, treatment, pretest, posttest))
}

electric.power <- function(n, n.sims=1000){
  signif <- rep(NA, n.sims)
  for(s in 1:n.sims){
    fake <- electric.fake(n)
    lm.power <- lm(posttest~pretest+treatment, data=fake)
    theta.hat <- coef(lm.power)[3]
    theta.se <- sqrt(vcov(lm.power)[3,3])
    signif[s] <- (theta.hat-2*theta.se) > 0
  }
  power <- mean(signif)
  return(power)
}


pow <- sapply(as.list(seq(48,64,by=2)), electric.power)
powd <- cbind.data.frame(n=seq(48,64,by=2), pow)
powd
@

{\it A sample size of $56$, $28$ in each group is required to achieve a power of $80\%$.}

\item Write up the results to explain to a consulting client how large a sample size is needed. \\

{\it If the goal is to detect a difference of $5$ points in the mean posttest scores between treated and control groups, and you assume equal sample sizes between groups and a pooled standard deviation of $11$, you will need $77$ classes in each group to attain a power of $80\%$. \\

If the goal is to detect a difference of $5$ points in the average gain scores (posttest-pretest) between treated and control groups, and you assume equal sample sizes between groups and a pooled standard deviation of $6$, you will need $24$ classes in each treatment group to attain a power of $80\%$. The above results can be found for different standard deviations and different effect sizes. Note that the sample size for gain scores is smaller because gain scores are estimated to be less variable than posttest scores. \\

In the simulation, we assume that the difference in posttest scores between treated and untreated groups in the existing sample is representative of the population. If you, as the researcher, have reason to believe that the current sample of second graders is not representative, then the results of this power analysis cannot be trusted. We first fit a regression model to the sample data, and then we create fake data by simulating pretest scores and treatment groups. We use the estimated regression model and the fake pretest scores and treatment groups to simulate the posttest scores. The estimated treatment effect from the regression model is the assumed effect size, $4.27$ in this case, and the variability estimate also comes from the existing regression model. Under these assumptions, we found that a sample size of $28$ classes in each treatment group achieves a power of $80\%$. \\

In the simulation, we account for pretest in the estimated regression model. So, simulation is another method for determining the sample size needed to detect a differece in the average gain scores. In practice, if you do plan to account for pretest score in your analysis, I would use the estimated sample size of $28$ per group (found by simulation) because it is more conservative than the estimate found with the parametric approach. \\

Scope of Inference: This power analysis is only meant to be used for further studies with the same population of second grade students and the same sampling design (with classes as the experimental units). We do not intend this analysis to be used in any other context because the variability estimates, effect sizes, and appropriate significance levels were estimated specifically for this Electric Company study.

}



\end{enumerate}

\end{enumerate}

{\Large \bf R Code Appendix}

<<draw, eval=FALSE>>=
@

<<powercalc, eval=FALSE>>=
@

<<bringpower, eval=FALSE>>=
@

<<ttest, eval=FALSE>>=
@

<<sd, eval=FALSE>>=
@

<<powercows, eval=FALSE>>=
@

<<bringpowerclass, eval=FALSE>>=
@

<<ttestclass, eval=FALSE>>=
@

<<bringpowergain, eval=FALSE>>=
@

<<ttestgain, eval=FALSE>>=
@

<<sim, eval=FALSE>>=
@




\end{document}